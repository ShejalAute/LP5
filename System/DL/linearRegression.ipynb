{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625ede4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5366c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf16e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train , y_train), (X_test , y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "                                            path = 'boston_housing_npz',\n",
    "                                            test_split = 0.2,\n",
    "                                            seed = 42\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1d499a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.279</td>\n",
       "      <td>74.5</td>\n",
       "      <td>4.0522</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>373.66</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.31827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.2</td>\n",
       "      <td>3.9986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>390.70</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.29090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.174</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.08</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.03841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.229</td>\n",
       "      <td>90.7</td>\n",
       "      <td>3.0993</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.33</td>\n",
       "      <td>12.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1      2    3      4      5     6       7     8      9     10  \\\n",
       "0  0.09178   0.0   4.05  0.0  0.510  6.416  84.1  2.6463   5.0  296.0  16.6   \n",
       "1  0.05644  40.0   6.41  1.0  0.447  6.758  32.9  4.0776   4.0  254.0  17.6   \n",
       "2  0.10574   0.0  27.74  0.0  0.609  5.983  98.8  1.8681   4.0  711.0  20.1   \n",
       "3  0.09164   0.0  10.81  0.0  0.413  6.065   7.8  5.2873   4.0  305.0  19.2   \n",
       "4  5.09017   0.0  18.10  0.0  0.713  6.297  91.8  2.3682  24.0  666.0  20.2   \n",
       "5  0.10153   0.0  12.83  0.0  0.437  6.279  74.5  4.0522   5.0  398.0  18.7   \n",
       "6  0.31827   0.0   9.90  0.0  0.544  5.914  83.2  3.9986   4.0  304.0  18.4   \n",
       "7  0.29090   0.0  21.89  0.0  0.624  6.174  93.6  1.6119   4.0  437.0  21.2   \n",
       "8  4.03841   0.0  18.10  0.0  0.532  6.229  90.7  3.0993  24.0  666.0  20.2   \n",
       "9  0.22438   0.0   9.69  0.0  0.585  6.027  79.7  2.4982   6.0  391.0  19.2   \n",
       "\n",
       "       11     12  \n",
       "0  395.50   9.04  \n",
       "1  396.90   3.53  \n",
       "2  390.11  18.07  \n",
       "3  390.91   5.52  \n",
       "4  385.09  17.27  \n",
       "5  373.66  11.97  \n",
       "6  390.70  18.33  \n",
       "7  388.08  24.16  \n",
       "8  395.33  12.87  \n",
       "9  396.90  14.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "# Preview the training data\n",
    "X_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640647e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8caa522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad997f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4371b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7187192203856405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa14aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8fac04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Dense(128,activation = 'relu',input_dim =13))\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Dense(16,activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = 'adam',loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d980105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 4s 6ms/step - loss: 532.0444\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 366.6518\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 142.2215\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 68.5120\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.6555\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 27.2430\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.3300\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8372\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.3848\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.9739\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 16.2680\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 15.0307\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 14.6226\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 13.7714\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.3127\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 13.0294\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 12.3402\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.7922\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.4433\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 11.6441\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.8890\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.4900\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.3186\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 10.2452\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 9.8457\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.5390\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 9.4251\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8958\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.2281\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 8.8216\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.7840\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 8.4883\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3316\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.1431\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0301\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.2663\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2755\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.2995\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.1754\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.0713\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 7.0928\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.8653\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.6286\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5039\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.4542\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.2911\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.0257\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 6.0304\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.5046\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6.2695\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.9781\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.0522\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.6218\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.5110\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.4716\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.2423\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.3414\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.1760\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.2613\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 5.1677\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.9477\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.9999\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.9452\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7736\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2407\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.9088\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.7295\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6253\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.7122\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5272\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.8691\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.4434\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.7383\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.0818\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.9430\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.0824\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.8899\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4.0508\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.9483\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.7579\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.7436\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6633\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5199\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.6912\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.5242\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4119\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3583\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3525\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2919\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.6854\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2308\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5101\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3661\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4399\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1362\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0814\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1247\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9089\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9473\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.8301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x151ec8f5150>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110739de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae6166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0085504435669024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee7cb5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24.533161], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# View the first prediction\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c0163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
